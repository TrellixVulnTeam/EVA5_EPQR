# Session 14

* Hardhat, Vest, Mask, and Boots Annotated Dataset [Link](https://drive.google.com/file/d/1EqtOpF7cS74C56EaVQoKNkQmpT6_HFL2/view?usp=sharing)

* Monocular Depth Estimation Images Dataset [Link](https://drive.google.com/drive/folders/16Ni8NxRDH_dz9ejz7lHOrOcAKO2a2Hm3?usp=sharing)

* 3D Plane Detection and Reconstruction from a Single Image Dataset [Link](https://drive.google.com/drive/folders/10lzwIEBFvRJqA5FlbEE3FYXIDp-IIhFd?usp=sharing).
(The smaller folder contains only the plane images while the other one contains all the output generated by the network).

---

SO, we collected the dataset containing the images (3590 images) of people wearing hardhat, vest, mask, and boots and annotated them using [YoloV3_Annotation_Tool](https://github.com/miki998/YoloV3_Annotation_Tool).
The first link contains this dataset (images and the .txt files for each image's labels depicting the position of the bounding boxes drawn).

NEXT, in order to get the inverse depth images, we made inference on [this](https://github.com/intel-isl/MiDaS) pretrained model on our collected dataset images.
The second link contains this dataset.

FINALLY, we made inference on [this](https://github.com/NVlabs/planercnn) pretrained model which uses MaskRCNN to get the planar regions in an image.
The third link contains this dataset.
